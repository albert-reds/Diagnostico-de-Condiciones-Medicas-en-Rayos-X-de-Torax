{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# NIH ChestX-ray14 \u2014 Comparativa (DenseNet121, EfficientNet\u2011B2, Swin\u2011T) + Inferencia con Gradio\n\n", "Notebook **final y limpio** para Google Colab. Incluye:\n", "- Montaje de Google Drive\n", "- Indexaci\u00f3n robusta en `images_0xx/**/images/*.(png|jpg|jpeg)`\n", "- Creaci\u00f3n de `train.csv`, `val.csv`, `test.csv` desde los archivos oficiales\n", "- Dataset/Dataloaders basados en `FILE_MAP` (sin rutas fr\u00e1giles)\n", "- Entrenamiento/evaluaci\u00f3n de **3 modelos** (configurable)\n", "- Interfaz **Gradio** para probar im\u00e1genes nuevas (+ Grad\u2011CAM para CNNs)\n\n", "**Antes de empezar:** `Entorno de ejecuci\u00f3n \u2192 Cambiar tipo de entorno \u2192 Acelerador de hardware: GPU`."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from google.colab import drive\n", "drive.mount('/content/drive', force_remount=True)\n", "\n", "DATA_DIR = \"/content/drive/MyDrive/datasets/NIH-ChestXray\"\n", "\n", "import os, platform, torch\n", "assert os.path.isdir(DATA_DIR), f\"\u274c No existe DATA_DIR: {DATA_DIR}\"\n", "print(\"\u2705 DATA_DIR:\", DATA_DIR)\n", "print(\"Python:\", platform.python_version())\n", "print(\"Torch :\", torch.__version__)\n", "print(\"CUDA disponible:\", torch.cuda.is_available())\n", "if torch.cuda.is_available():\n", "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os\n", "DATA_CSV = os.path.join(DATA_DIR, \"Data_Entry_2017.csv\")\n", "TRAIN_VAL_LIST = os.path.join(DATA_DIR, \"train_val_list.txt\")\n", "TEST_LIST = os.path.join(DATA_DIR, \"test_list.txt\")\n", "for p in [DATA_CSV, TRAIN_VAL_LIST, TEST_LIST]:\n", "    assert os.path.exists(p), f\"\u274c Falta {os.path.basename(p)} en {DATA_DIR}\"\n", "print(\"\u2705 Archivos oficiales detectados.\")\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from pathlib import Path\n", "def build_file_map(data_dir):\n", "    file_map = {}\n", "    roots = sorted([d for d in Path(data_dir).glob(\"images_*\") if d.is_dir()])\n", "    assert roots, \"\u274c No se encontraron carpetas images_0xx en DATA_DIR\"\n", "    exts = {\".png\",\".jpg\",\".jpeg\"}\n", "    total=0\n", "    for root in roots:\n", "        for p in root.rglob(\"*\"):\n", "            if p.is_file() and p.suffix.lower() in exts:\n", "                file_map[p.name] = str(p); total += 1\n", "    print(f\"   \u21b3 Escaneadas {len(roots)} carpetas 'images_0xx', archivos contados: {total}\")\n", "    return file_map\n", "\n", "FILE_MAP = build_file_map(DATA_DIR)\n", "print(\"\u2705 Im\u00e1genes indexadas (filename \u2192 ruta):\", len(FILE_MAP))\n", "for i,(k,v) in enumerate(FILE_MAP.items()):\n", "    if i>=3: break\n", "    print(\"  \", k, \"->\", v)\n", "assert len(FILE_MAP) > 0, \"\u274c No se indexaron im\u00e1genes. Revisa la estructura 'images_0xx/**/images/'.\"\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "from sklearn.model_selection import train_test_split\n", "\n", "df_all = pd.read_csv(DATA_CSV)\n", "with open(TRAIN_VAL_LIST, \"r\") as f:\n", "    train_val_files = [line.strip().split()[0] for line in f if line.strip()]\n", "with open(TEST_LIST, \"r\") as f:\n", "    test_files = [line.strip().split()[0] for line in f if line.strip()]\n", "\n", "df_trainval_raw = df_all[df_all[\"Image Index\"].isin(train_val_files)].copy()\n", "df_test_raw     = df_all[df_all[\"Image Index\"].isin(test_files)].copy()\n", "\n", "def keep_existing(df):\n", "    return df[df[\"Image Index\"].map(lambda x: x in FILE_MAP)].copy()\n", "\n", "df_trainval = keep_existing(df_trainval_raw)\n", "df_test     = keep_existing(df_test_raw)\n", "print(f\"\ud83d\udcd1 train_val con im\u00e1genes: {len(df_trainval)} | test con im\u00e1genes: {len(df_test)}\")\n", "assert len(df_trainval)>0, \"\u274c train_val qued\u00f3 vac\u00edo tras filtrar por im\u00e1genes existentes.\"\n", "\n", "def safe_split(df, test_size=0.10, seed=42):\n", "    y = df[\"Finding Labels\"].astype(str)\n", "    vc = y.value_counts()\n", "    can_stratify = (len(vc)>=2) and (vc.min()>=2) and (len(df)*test_size>=len(vc))\n", "    if can_stratify:\n", "        return train_test_split(df, test_size=test_size, random_state=seed, stratify=y)\n", "    else:\n", "        print(\"\u26a0\ufe0f Pocas muestras/clases \u2192 split sin estratificar.\")\n", "        return train_test_split(df, test_size=test_size, random_state=seed, shuffle=True)\n", "\n", "df_train, df_val = safe_split(df_trainval, test_size=0.10, seed=42)\n", "TRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\n", "VAL_CSV   = os.path.join(DATA_DIR, \"val.csv\")\n", "TEST_CSV  = os.path.join(DATA_DIR, \"test.csv\")\n", "df_train.to_csv(TRAIN_CSV, index=False)\n", "df_val.to_csv(VAL_CSV, index=False)\n", "df_test.to_csv(TEST_CSV, index=False)\n", "print(\"\ud83c\udfaf Guardados:\")\n", "print(\"  train.csv:\", len(df_train), \"\u2192\", TRAIN_CSV)\n", "print(\"  val.csv  :\", len(df_val),   \"\u2192\", VAL_CSV)\n", "print(\"  test.csv :\", len(df_test),  \"\u2192\", TEST_CSV)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import torch\n", "from torch.utils.data import Dataset, DataLoader\n", "from torchvision import transforms\n", "from PIL import Image\n", "\n", "IMAGENET_MEAN=[0.485,0.456,0.406]; IMAGENET_STD=[0.229,0.224,0.225]\n", "IMG_SIZE=224\n", "train_tfms = transforms.Compose([\n", "    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n", "    transforms.RandomHorizontalFlip(0.5),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n", "])\n", "eval_tfms = transforms.Compose([\n", "    transforms.Resize((IMG_SIZE,IMG_SIZE)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n", "])\n", "\n", "class ChestXrayDatasetFM(Dataset):\n", "    def __init__(self, csv_file, file_map, transform):\n", "        import pandas as pd\n", "        self.df = pd.read_csv(csv_file)\n", "        self.file_map = file_map\n", "        self.tfm = transform\n", "    def __len__(self): return len(self.df)\n", "    def __getitem__(self, idx):\n", "        r = self.df.iloc[idx]\n", "        fname = r[\"Image Index\"]\n", "        p = self.file_map.get(fname)\n", "        if p is None:\n", "            raise FileNotFoundError(f\"{fname} no hallado en FILE_MAP\")\n", "        img = Image.open(p).convert(\"RGB\")\n", "        x = self.tfm(img)\n", "        y = 0 if str(r[\"Finding Labels\"]).strip()==\"No Finding\" else 1\n", "        return x, torch.tensor(y, dtype=torch.long)\n", "\n", "BATCH=16\n", "NUM_WORKERS = 2 if torch.cuda.is_available() else 0\n", "try:\n", "    tmp_dl = DataLoader(ChestXrayDatasetFM(TRAIN_CSV, FILE_MAP, train_tfms), batch_size=BATCH, shuffle=True, num_workers=NUM_WORKERS, pin_memory=torch.cuda.is_available())\n", "    xb, yb = next(iter(tmp_dl))\n", "    print(\"\u2705 Dataloader OK. Batch ejemplo:\", xb.shape, yb.shape, \"| etiquetas:\", yb.unique().tolist())\n", "except Exception as e:\n", "    print(\"\u26a0\ufe0f Prueba de Dataloader fall\u00f3:\", e)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import torch.nn as nn\n", "from sklearn.metrics import accuracy_score, f1_score\n", "from torchvision.models import (\n", "    densenet121, DenseNet121_Weights,\n", "    efficientnet_b2, EfficientNet_B2_Weights,\n", "    swin_t, Swin_T_Weights\n", ")\n", "\n", "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "USE_PRETRAINED = True\n", "EPOCHS = 1\n", "BATCH = 16\n", "LR = 1e-4\n", "\n", "def build_densenet(num_classes=2):\n", "    w = DenseNet121_Weights.IMAGENET1K_V1 if USE_PRETRAINED else None\n", "    m = densenet121(weights=w)\n", "    m.classifier = nn.Linear(m.classifier.in_features, num_classes)\n", "    return m\n", "\n", "def build_efficientnet(num_classes=2):\n", "    w = EfficientNet_B2_Weights.IMAGENET1K_V1 if USE_PRETRAINED else None\n", "    m = efficientnet_b2(weights=w)\n", "    m.classifier[1] = nn.Linear(m.classifier[1].in_features, num_classes)\n", "    return m\n", "\n", "def build_swin(num_classes=2):\n", "    w = Swin_T_Weights.IMAGENET1K_V1 if USE_PRETRAINED else None\n", "    m = swin_t(weights=w)\n", "    m.head = nn.Linear(m.head.in_features, num_classes)\n", "    return m\n", "\n", "MODELS = {\n", "    \"densenet121\": build_densenet,\n", "    \"efficientnet_b2\": build_efficientnet,\n", "    \"swin_t\": build_swin,\n", "}\n", "\n", "def train_eval_model(model_fn, train_csv, val_csv, test_csv, file_map, epochs=EPOCHS, batch_size=BATCH, lr=LR):\n", "    ds_tr = ChestXrayDatasetFM(train_csv, file_map, train_tfms)\n", "    ds_va = ChestXrayDatasetFM(val_csv,   file_map, eval_tfms)\n", "    ds_te = ChestXrayDatasetFM(test_csv,  file_map, eval_tfms)\n", "\n", "    nw = 2 if torch.cuda.is_available() else 0\n", "    dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True,  num_workers=nw, pin_memory=torch.cuda.is_available())\n", "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=nw)\n", "    dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=nw)\n", "\n", "    model = model_fn().to(DEVICE)\n", "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n", "    loss_fn = nn.CrossEntropyLoss()\n", "\n", "    for ep in range(epochs):\n", "        model.train()\n", "        for x,y in dl_tr:\n", "            x,y = x.to(DEVICE), y.to(DEVICE)\n", "            opt.zero_grad(); loss = loss_fn(model(x), y); loss.backward(); opt.step()\n", "\n", "    def eval_dl(dl):\n", "        y_true, y_pred = [], []\n", "        model.eval()\n", "        with torch.no_grad():\n", "            for x,y in dl:\n", "                x,y = x.to(DEVICE), y.to(DEVICE)\n", "                preds = model(x).argmax(1)\n", "                y_true += y.cpu().tolist(); y_pred += preds.cpu().tolist()\n", "        return accuracy_score(y_true,y_pred), f1_score(y_true,y_pred, average=\"macro\")\n", "\n", "    tr_acc, tr_f1 = eval_dl(dl_tr)\n", "    va_acc, va_f1 = eval_dl(dl_va)\n", "    te_acc, te_f1 = eval_dl(dl_te)\n", "    return {\"train_acc\":tr_acc,\"train_f1\":tr_f1,\"val_acc\":va_acc,\"val_f1\":va_f1,\"test_acc\":te_acc,\"test_f1\":te_f1}\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pandas as pd\n", "results = []\n", "for name, fn in MODELS.items():\n", "    print(f\"=== Entrenando {name} ===\")\n", "    mets = train_eval_model(fn, TRAIN_CSV, VAL_CSV, TEST_CSV, FILE_MAP)\n", "    results.append({\"model\":name, **mets})\n", "df = pd.DataFrame(results)\n", "display(df)\n", "OUT_CSV = os.path.join(DATA_DIR, \"resultados_3_modelos.csv\")\n", "df.to_csv(OUT_CSV, index=False)\n", "print(\"\ud83d\udcc4 Guardado:\", OUT_CSV)\n"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["!pip -q install gradio==4.44.0\n", "import gradio as gr\n", "from torchvision import transforms\n", "from PIL import Image\n", "import numpy as np, os\n", "\n", "CLASS_NAMES = [\n", "    \"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",\n", "    \"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\n", "    \"Pleural_Thickening\",\"Hernia\"\n", "]\n", "infer_tfms = transforms.Compose([\n", "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n", "])\n", "MODEL_FACTORY = {\n", "    \"densenet121\": build_densenet,\n", "    \"efficientnet_b2\": build_efficientnet,\n", "    \"swin_t\": build_swin,\n", "}\n", "def load_model_for_inference(model_name: str, num_classes: int = 14, ckpt_path: str = \"\"):\n", "    model = MODEL_FACTORY[model_name](num_classes=num_classes).to(DEVICE).eval()\n", "    if ckpt_path and os.path.exists(ckpt_path):\n", "        state = torch.load(ckpt_path, map_location=DEVICE)\n", "        if isinstance(state, dict) and \"state_dict\" in state: state = state[\"state_dict\"]\n", "        try:\n", "            model.load_state_dict(state, strict=False)\n", "        except Exception:\n", "            new_state = {}\n", "            for k,v in (state.items() if isinstance(state, dict) else []): new_state[k.replace(\"module.\",\"\")] = v\n", "            model.load_state_dict(new_state, strict=False)\n", "    return model\n", "def gradcam_quick(model: nn.Module, pil_img: Image.Image):\n", "    import torch.nn.functional as F, cv2\n", "    last_conv = None\n", "    for m in model.modules():\n", "        if isinstance(m, nn.Conv2d): last_conv = m\n", "    if last_conv is None: return None\n", "    activations, gradients = [], []\n", "    def fwd_hook(_, __, out): activations.append(out.detach())\n", "    def bwd_hook(_, grad_in, grad_out): gradients.append(grad_out[0].detach())\n", "    h1 = last_conv.register_forward_hook(fwd_hook)\n", "    h2 = last_conv.register_full_backward_hook(bwd_hook)\n", "    model.eval()\n", "    x = infer_tfms(pil_img).unsqueeze(0).to(DEVICE); x.requires_grad_(True)\n", "    out = model(x); score = out[0].max(); model.zero_grad(set_to_none=True); score.backward()\n", "    act = activations[-1][0]; grad = gradients[-1][0]\n", "    w = grad.mean(dim=(1,2), keepdim=True); cam = (w*act).sum(dim=0); cam = F.relu(cam); cam = cam/(cam.max()+1e-6)\n", "    cam = cam.cpu().numpy()\n", "    import cv2, numpy as np\n", "    img_np = np.array(pil_img.convert(\"RGB\"))\n", "    cam_resized = cv2.resize(cam, (img_np.shape[1], img_np.shape[0]))\n", "    heatmap = cv2.applyColorMap(np.uint8(255*cam_resized), cv2.COLORMAP_JET)\n", "    overlay = np.uint8(0.4*heatmap + 0.6*img_np)\n", "    h1.remove(); h2.remove(); from PIL import Image as PImage\n", "    return PImage.fromarray(overlay)\n", "import torch\n", "@torch.no_grad()\n", "def predict_one(img: Image.Image, model_name: str, ckpt_path: str, topk: int, threshold: float):\n", "    model = load_model_for_inference(model_name, num_classes=14, ckpt_path=ckpt_path)\n", "    x = infer_tfms(img).unsqueeze(0).to(DEVICE)\n", "    logits = model(x)\n", "    import numpy as np\n", "    probs = torch.sigmoid(logits)[0].cpu().numpy()\n", "    idxs = np.argsort(-probs)[:topk]\n", "    top_rows = [(CLASS_NAMES[i], float(probs[i])) for i in idxs]\n", "    above = [(CLASS_NAMES[i], float(probs[i])) for i in range(len(CLASS_NAMES)) if probs[i] >= threshold]\n", "    above = sorted(above, key=lambda t: -t[1])\n", "    cam_img = None\n", "    if model_name in (\"densenet121\",\"efficientnet_b2\"):\n", "        try: cam_img = gradcam_quick(model, img)\n", "        except Exception: cam_img = None\n", "    return top_rows, above, cam_img\n", "with gr.Blocks(title=\"ChestX-ray14 Inference\") as demo:\n", "    gr.Markdown(\"## \ud83e\ude7b ChestX\u2011ray14 \u2013 Prueba con im\u00e1genes nuevas\")\n", "    with gr.Row():\n", "        with gr.Column(scale=1):\n", "            img_in = gr.Image(type=\"pil\", label=\"Sube radiograf\u00eda (PNG/JPG)\")\n", "            model_dd = gr.Dropdown(choices=list(MODEL_FACTORY.keys()), value=\"densenet121\", label=\"Modelo\")\n", "            ckpt_tb = gr.Textbox(value=\"\", label=\"Ruta de checkpoint (.pth/.pt) en Drive (opcional)\")\n", "            topk_sl = gr.Slider(1, 14, value=5, step=1, label=\"Top\u2011k\")\n", "            thr_sl  = gr.Slider(0.05, 0.95, value=0.5, step=0.05, label=\"Umbral multi\u2011label\")\n", "            btn = gr.Button(\"Predecir\", variant=\"primary\")\n", "        with gr.Column(scale=1):\n", "            out_top = gr.Dataframe(headers=[\"Clase\",\"Probabilidad\"], label=\"Top\u2011k\", interactive=False)\n", "            out_thr = gr.Dataframe(headers=[\"Clase\",\"Probabilidad\"], label=\"\u2265 umbral\", interactive=False)\n", "            out_cam = gr.Image(type=\"pil\", label=\"Grad\u2011CAM (solo CNNs)\")\n", "    btn.click(predict_one, inputs=[img_in, model_dd, ckpt_tb, topk_sl, thr_sl], outputs=[out_top, out_thr, out_cam])\n", "demo.launch(debug=False, share=False)\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 5}